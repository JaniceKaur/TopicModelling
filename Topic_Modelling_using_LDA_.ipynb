{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaC0TOsZy7NF"
   },
   "source": [
    "# Latent Dirichlet Allocation(LDA)\n",
    "\n",
    "**Topic modeling** is a method for unsupervised classification of documents, similar to clustering on numeric data, which finds some natural groups of items (topics) even when we’re not sure what we’re looking for.\n",
    "\n",
    "**LDA Assumptions:**\n",
    "\n",
    "*   Each document is just a collection of words or a “bag of words”. Thus, the order of the words and the grammatical role of the words (subject, object, verbs, …) are not considered in the model.\n",
    "\n",
    "*   Words like am/is/are/of/a/the/but/… don’t carry any information about the “topics” and therefore can be eliminated from the documents as a preprocessing step. In fact, we can eliminate words that occur in at least %80 ~ %90 of the documents, without losing any information.\n",
    "For example, if our corpus contains only medical documents, words like human, body, health, etc might be present in most of the documents and hence can be removed as they don’t add any specific information which would make the document stand out.\n",
    "\n",
    "*   We know beforehand how many topics we want. ‘k’ is pre-decided.\n",
    "\n",
    "*   All topic assignments except for the current word in question are correct, and then updating the assignment of the current word using our model of how documents are generated\n",
    "\n",
    "`p(word w with topic t) = p(topic t | document d) * p(word w | topic t)`\n",
    "\n",
    "More Info at https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr = pd.read_csv('npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  In the Washington of 2016, even when the polic...\n",
       "1    Donald Trump has used Twitter  —   his prefe...\n",
       "2    Donald Trump is unabashedly praising Russian...\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4  From photography, illustration and video, to d..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The headline shocked the   world of the surface Navy: Seven sailors aboard the destroyer USS Fitzgerald were killed, and other crew members injured, when the warship collided with a cargo vessel off Japan. As the Navy family grieves, both it and the wider world are asking the same question: How did this happen? The short answer is that no one knows  —   yet. Official inquiries into what led up to the encounter could take months or more. The Navy and the U. S. Coast Guard both likely will eventually issue reports that describe what happened and could make recommendations for preventing another such accident. ”I will not speculate on how long these investigations will last,” said Vice Adm. Joseph Aucoin, commander of the Navy’s 7th Fleet. The Fitzgerald and the other ships of Destroyer Squadron 15, based outside Tokyo, fall under his authority. There are clues, however, that explain how something like the Fitzgerald’s collision could happen, including photographs of the ships involved, navigation data about the container ship ACX Crystal and the experience the Navy has had with past mishaps. The $1. 8 billion Fitzgerald is one of the most modern and technologically advanced warships afloat, capable of using its powerful sensors to look up into space, if necessary, and reach up to hit targets there with its battery of missiles. The destroyer still has a human crew, however, most of which was likely asleep around 2:30 a. m. local time when it collided with the Crystal. There was no moon over the waters south of Tokyo Bay, according to local accounts, and the channel there is frequently crowded with ships on their way into and out of the Japanese capital. Vessels of all sizes sail to other ports in Asia or head east into the vast Pacific. Sailors in the Fitzgerald’s combat information center and on its bridge are responsible for using the ship’s sensors to plot the location of each one, as well as the directions they’re headed and the speed at which they’re sailing. Officers and sailors must at all times keep what the Navy calls good ”situational awareness” about not only what their own ship is doing, but about what might be ahead in the next patch of ocean where the Fitzgerald wants to sail. In 2012 a sibling of the Fitzgerald, the destroyer USS Porter, was in a congested,   seaway called the Strait of Hormuz  —   the ribbon of water that connects the Persian Gulf with the Arabian Sea  —   when it collided with an oil tanker. The Navy’s investigation later found that as sailors tried to keep track of the traffic all around them, including those ships headed the other direction, they lost focus on their own immediate course ahead. When the tanker Otowasan suddenly loomed ahead, Cmdr. Martin Arriola ordered the Porter to turn left to cross ahead of the huge other ship to avoid a   crash. But he hadn’t done so with enough time, and not even ordering full speed at the last minute could get the destroyer safely clear. The Otowasan hit the Porter along its right  —   or starboard  —   side, in a location on the ship very near where the ACX Crystal hit the Fitzgerald early Saturday. But when the sun came up and photos appeared of both ships, they revealed the Crystal had damage on the left or port side of its bow  —   suggesting it might have been traveling in the same direction as the Fitzgerald. It may have been trailing the smaller destroyer at a perpendicular angle that stayed relatively the same even as the distance between the ships closed: ”constant bearing, decreasing range.” If the crew of the Fitzgerald was watching what was ahead of them and got used to the presence of the container ship on their starboard quarter because it didn’t appear to be moving in either direction relative to the destroyer  —   even though it was getting closer all the while  —   the sailors might not have realized what was happening until they were in extremis. Another similar possibility: the Fitzgerald wanted to sail east, say, and its course crossed over that of the Crystal, heading north. The destroyer might have been like someone trying to get across a busy street, thinking it could get out of the way of the oncoming cars in time  —   in this case, a miscalculation. Investigators will focus closely on what the crews on both ships were doing. When the fast attack submarine USS Hartford collided with the amphibious transport USS New Orleans in 2009, discipline on the sub was lax, the Navy later found. The Hartford’s captain never came into the control room during the transit through the crowded Strait of Hormuz. The navigator was in the wardroom listening to his iPod. It’s possible that no one was on the bridge of the Crystal  —   even huge container ships are comparatively lightly crewed, compared with Navy ships, and unlike warships, often use an autopilot. In the wide open Pacific, mariners sometimes let ”Iron Mike” take the helm. After a series of accidents, the U. S. Coast Guard warned mariners last year about the dangers involved with relying too heavily on autopilot. The Fitzgerald’s bridge almost certainly was crewed, by sailors and officers on the overnight ”midwatch” and those are the watchstanders who may have made the critical decisions about what to do or not do before the collision. Were they managing a whole screen full of contacts and too distracted to notice the one bearing down on them? Or was it a quiet night with so little to do that the crew became bored and complacent? Investigators will conduct interviews, review navigational data and could even listen to recordings of what happened on the bridge, like the one eventually released from the Porter. One detail already is known: The Fitzgerald’s commanding officer, Cmdr. Bryce Benson, was in his cabin at the time of the accident, 7th Fleet’s Aucoin said. The captain’s compartment is located on the starboard side of the ship that was crushed by the Crystal, and Benson was hurt  —   the Japanese Coast Guard took him to shore by helicopter. Other sailors were berthed in compartments farther below decks, which were flooded by the Crystal’s bulbous bow. In all, two berthing compartments and one machinery space, which houses one of the gas turbines for making the ship’s electrical power, quickly filled with seawater. ”Heroic efforts prevented the flooding from catastrophically spreading, which could have caused the ship to founder or sink,” Aucoin said. ”It could have been much worse.” The Fitzgerald limped into Tokyo under its own power the crew of the   Aegis combatant used a magnetic compass and their backup instruments to get home with only one of the ship’s two propellers. The destroyer now needs millions of dollars’ worth of repairs, including a visit to a dry dock, before it could be ready to take another mission. The Navy identified the seven sailors who died in the accident on Sunday evening. Acting Navy Secretary Sean Stackley vowed that service officials would answer the question everyone is now asking: how it could have happened. ”In due time, the United States Navy will fully investigate the cause of this tragedy,” he said, ”and I ask all of you to keep the Fitzgerald families in your thoughts and prayers as we begin the task of answering the many questions before us.”'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr['Article'][4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.9,min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = cv.fit_transform(npr['Article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11992x54777 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3033388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=7, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=7, random_state=42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding Vocabulary of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54777"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transcribe'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()[50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.64332806e+00, 2.38014333e+03, 1.42900522e-01, ...,\n",
       "        1.43006821e-01, 1.42902042e-01, 1.42861626e-01],\n",
       "       [2.76191749e+01, 5.36394437e+02, 1.42857148e-01, ...,\n",
       "        1.42861973e-01, 1.42857147e-01, 1.42906875e-01],\n",
       "       [7.22783888e+00, 8.24033986e+02, 1.42857148e-01, ...,\n",
       "        6.14236247e+00, 2.14061364e+00, 1.42923753e-01],\n",
       "       ...,\n",
       "       [3.11488651e+00, 3.50409655e+02, 1.42857147e-01, ...,\n",
       "        1.42859912e-01, 1.42857146e-01, 1.42866614e-01],\n",
       "       [4.61486388e+01, 5.14408600e+01, 3.14281373e+00, ...,\n",
       "        1.43107628e-01, 1.43902481e-01, 2.14271779e+00],\n",
       "       [4.93991422e-01, 4.18841042e+02, 1.42857151e-01, ...,\n",
       "        1.42857146e-01, 1.43760101e-01, 1.42866201e-01]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the words that occur in a topic\n",
    "LDA.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 54777)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words for the first topic\n",
    "first_topic = LDA.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2475, 18302, 35285, ..., 22673, 42561, 42993])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_topic.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33390, 36310, 21228, 10425, 31464,  8149, 36283, 22673, 42561,\n",
       "       42993])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the top 10 occuring in a topic (highest to lowest in occurence)\n",
    "first_topic.argsort()[-10:] #stored as indices to the cv array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new\n",
      "percent\n",
      "government\n",
      "company\n",
      "million\n",
      "care\n",
      "people\n",
      "health\n",
      "said\n",
      "says\n"
     ]
    }
   ],
   "source": [
    "# getting the words\n",
    "for i in first_topic.argsort()[-10:]:\n",
    "    print(cv.get_feature_names()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for Topic 1 :\n",
      "['npr', 'reports', 'says', 'news', 'people', 'told', 'police', 'president', 'trump', 'said']\n",
      "\n",
      "\n",
      "Top 10 words for Topic 2 :\n",
      "['time', 'water', 'city', 'new', 'years', 'food', 'just', 'people', 'like', 'says']\n",
      "\n",
      "\n",
      "Top 10 words for Topic 3 :\n",
      "['disease', 'patients', 'just', 'children', 'study', 'like', 'women', 'health', 'people', 'says']\n",
      "\n",
      "\n",
      "Top 10 words for Topic 4 :\n",
      "['obama', 'court', 'republican', 'campaign', 'people', 'state', 'president', 'clinton', 'said', 'trump']\n",
      "\n",
      "\n",
      "Top 10 words for Topic 5 :\n",
      "['new', 'way', 'music', 'really', 'time', 'know', 'think', 'people', 'just', 'like']\n",
      "\n",
      "\n",
      "Top 10 words for Topic 6 :\n",
      "['people', 'time', 'schools', 'just', 'education', 'new', 'like', 'students', 'school', 'says']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Grabbing The highest probability words per topic\n",
    "for i in range(1,LDA.components_.shape[0]):\n",
    "    print(f\"Top 10 words for Topic {i} :\")\n",
    "    print([cv.get_feature_names()[ind] for ind in LDA.components_[i].argsort()[-10:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11992, 7)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02, 0.68, 0.  , 0.  , 0.3 , 0.  , 0.  ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probabilities that the document belongs to which topic\n",
    "results[0].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr['Topic']=results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11987</th>\n",
       "      <td>The number of law enforcement officers shot an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11988</th>\n",
       "      <td>Trump is busy these days with victory tours,...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11989</th>\n",
       "      <td>It’s always interesting for the Goats and Soda...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11990</th>\n",
       "      <td>The election of Donald Trump was a surprise to...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11991</th>\n",
       "      <td>Voters in the English city of Sunderland did s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Article  Topic\n",
       "0      In the Washington of 2016, even when the polic...      1\n",
       "1        Donald Trump has used Twitter  —   his prefe...      1\n",
       "2        Donald Trump is unabashedly praising Russian...      1\n",
       "3      Updated at 2:50 p. m. ET, Russian President Vl...      1\n",
       "4      From photography, illustration and video, to d...      2\n",
       "...                                                  ...    ...\n",
       "11987  The number of law enforcement officers shot an...      1\n",
       "11988    Trump is busy these days with victory tours,...      4\n",
       "11989  It’s always interesting for the Goats and Soda...      3\n",
       "11990  The election of Donald Trump was a surprise to...      4\n",
       "11991  Voters in the English city of Sunderland did s...      0\n",
       "\n",
       "[11992 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Topic Modelling using LDA .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
